{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPUBkIXgEj3fDVRVekmD7kS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Neural network algorithm\n","## Hebbian learning\n","\n","#### Neurons that **fire** together **wire** together\n","* In a Biological Neural Network, if a neuron excites another neuron, they\n","will come closer (have strong/tight synaptic connections). In Artificial Neural Network (ANN), this is implemented as increased weight between input and output neuron.\n","\n","* The original 'Hebb rule' defined firing as if input neuron X is 1(Fired) then output neuron Y is also 1(Fired); The extended 'Hebb rule' adds, if X is 0(Non-fired/OFF) then Y is also 0 (Non-fired/OFF) is also considered as '*firing*'\n","\n","* A single layer feedforward neural network is implemented below, the architecture uses 'Hebb rule' for learning and therefore known as 'Hebb net'.\n","\n","* The following Python code demonstrates how a minimal and single layer neural net can be used to train several input vectors to learn pattern of logical AND gate.\n","\n","* The Hebbian learning algorithm mentioned below requires target value for training, and hense demonstrates supervised learning.\n","\n","* For each input pattern, algorithm calculates the activation value and using Bias/threshold criteria it fires the target/output neuron\n"],"metadata":{"id":"eJTlfsej8L1k"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8_t9bS_D7hWC","executionInfo":{"status":"ok","timestamp":1740481101126,"user_tz":-330,"elapsed":36,"user":{"displayName":"Deepak Sharma","userId":"13663355715438175254"}},"outputId":"69fe2a4d-ff48-44cb-949d-a3252b123aa7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input vector patterns =  4 & Input neurons =  3\n","Initial weights for synapses = [0 0 0]\n","\n","For input vector pattern no. 1 [1 1 1]\n","Activation :  0\n","New weights : [1 1 1] = Current weights : [0 0 0] + Weight change: [1 1 1]\n","\n","For input vector pattern no. 2 [ 1 -1  1]\n","Activation :  1\n","New weights : [0 2 0] = Current weights : [1 1 1] + Weight change: [-1  1 -1]\n","\n","For input vector pattern no. 3 [-1  1  1]\n","Activation :  2\n","New weights : [ 1  1 -1] = Current weights : [0 2 0] + Weight change: [ 1 -1 -1]\n","\n","For input vector pattern no. 4 [-1 -1  1]\n","Activation :  -3\n","New weights : [ 2  2 -2] = Current weights : [ 1  1 -1] + Weight change: [ 1  1 -1]\n","\n","Weights after Hebbian learning = [ 2  2 -2]\n","\n","Testing neural network learning\n","Test case is [1, -1, 1] and predicted output is -1\n"]}],"source":["import numpy as np # Imports numpy library to generate/represent arrays and matrices\n","def hebb_net(X, Y): # Takes possible input neuron ON/OFF patterns\n","    num_samples, num_features = X.shape # Figures out number of data points (patterns) and features (neurons+bias)\n","    print(\"Input vector patterns = \",num_samples,\"& Input neurons = \",num_features) # Prints shape of Neural network\n","    weights = np.zeros(num_features, dtype=int)  # Assign initial weights to be zero\n","    print(\"Initial weights for synapses =\", weights)\n","    for i in range(num_samples):\n","        print(\"\\nFor input vector pattern no.\",i+1, X[i])\n","        y_pred = np.dot(X[i], weights) # Activation\n","        print(\"Activation : \",y_pred)\n","        delta_w = X[i] * Y[i]  # Supervised learning using Hebbian rule using target Y - The rule calculates required weight change\n","        print(\"New weights :\", weights + delta_w, \"= Current weights :\", weights, \"+ Weight change:\", delta_w)\n","        weights += delta_w\n","    return weights\n","\n","# X = np.array([ # Binary input vector patterns\n","#     [1, 1, 1],\n","#     [1, 0, 1],\n","#     [0, 1, 1],\n","#     [0, 0, 1]])\n","X = np.array([ # Bipolar input vector patterns\n","    [1,   1, 1],\n","    [1,  -1, 1],\n","    [-1,  1, 1],\n","    [-1, -1, 1]])\n","\n","# Target output (Actual output) for AND gate\n","# Y = np.array([1, 0, 0, 0]) # Binary output\n","Y = np.array([1, -1, -1, -1]) # Bipolar output\n","\n","# Target output (Actual output) for OR gate\n","# Y = np.array([1, 1, 1, 0]) # Binary output\n","# Y = np.array([1, 1, 1, -1]) # Bipolar output\n","\n","learned_weights = hebb_net(X, Y) # Train the Hebb Net\n","print(\"\\nWeights after Hebbian learning =\", learned_weights) # Print weights vector\n","\n","def predict(x, weights): # Predict target for given input pattern\n","    if np.dot(x, weights) > 0:\n","        return 1\n","    else:\n","        return -1 # Keep -1 for Bipolar output neuron and 0 for Binary neuron\n","\n","print(\"\\nTesting neural network learning\")\n","\n","test_case = [1,  1, 1]\n","test_case = [1,  -1, 1]\n","# test_case = [-1,  1, 1]\n","# test_case = [-1,  -1, 1]\n","\n","prediction = predict(test_case, learned_weights)\n","print(\"Test case is\",test_case, \"and predicted output is\",prediction)\n","\n"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","def graph_coordinates():\n","    x_range = np.array([-2, 2]) # x range\n","    y_range = np.array([-2, 2]) # y range\n","    fig, ax = plt.subplots() # Create the figure and axes\n","    ax.set_xlim(x_range) # Set the x axis limit\n","    ax.set_ylim(y_range) # Set the y axis limit\n","    ax.axhline(0, color='gray', linewidth=1) # Draw the x axis\n","    ax.axvline(0, color='gray', linewidth=1) # Draw the y axis\n","    # ax.text(0.2, -0.4, 'Origin (0, 0)', fontsize=10) # Add a label for the origin\n","    ax.set_aspect('equal', adjustable='box') # Set the aspect ratio to be equal\n","    ax.set_xticks([-2,-1,0,1,2]) # Remove the x ticks\n","    ax.set_yticks([-2,-1,0,1,2]) # Remove the y ticks"],"metadata":{"id":"6C6nkkVp8SKD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = [0,1,0,1]\n","y = [0,0,1,1]\n","line_x = [1, 0]\n","line_y = [0, 1]\n","plt.plot(line_x, line_y)\n","plt.show()"],"metadata":{"id":"ap457nmq8UWO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def addpoints(test_case,prediction):\n","    if(prediction == 1):\n","        color = \"green\"\n","    else:\n","        color = \"red\"\n","    plt.scatter(test_case[0],test_case[1],color = color)\n","\n","graph_coordinates()\n","addpoints(test_case,-1)\n","addpoints([-1,1,1],-1)\n","addpoints([1,-1,1],-1)\n","addpoints([1,1,1],1)\n","addpoints([-1,-1,1],1)\n","plt.plot(line_x, line_y)\n","plt.show()"],"metadata":{"id":"t5boy1Mf8R9I"},"execution_count":null,"outputs":[]}]}